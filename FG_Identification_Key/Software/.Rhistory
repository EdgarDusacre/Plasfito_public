"ES2 = Orrua",
"ES3 = Alkolea",
"ES4 = Gorrondatxe"))
Plasfito <- ggplot() +
# Add white background
geom_rect(aes(xmin = -5.2, xmax = -0.0, ymin = 42.8, ymax = 48.25),
fill = "white", color = NA) +
# Add Plasfito area with legend
geom_rect(data = studied_area_df, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = area),
color = NA, alpha = 1) +
scale_fill_manual(values = c("Studied area" = "#80CAD0"), name = "") +
# Add background continent
geom_sf(data = europe_high_res, fill = "lightgrey", color = "black", size = 0.2) +
# Add frontier regions
geom_sf(data = nouvelle_aquitaine, fill = NA, color = "black", size = 3) +
geom_sf(data = BC, fill = NA, color = "black", size = 3) +
# Add north arrow
annotation_north_arrow(location = "tr",
which_north = "true",
pad_x = unit(0.1, "in"), pad_y = unit(0.2, "in"),
style = north_arrow_fancy_orienteering,
height = unit(1, "cm"), width = unit(1, "cm")) +
# Add scale bar
annotation_scale(location = "br", width_hint = 0.3, text_cex = 0.7,
pad_x = unit(0.2, "cm"), pad_y = unit(0.4, "cm"),
style = "bar", bar_cols = c("black", "white"),
line_width = 1, height = unit(0.2, "cm"),
text_family = "sans", text_face = "bold") +
# Add sampling beaches
geom_point(data = Sampled_beaches, aes(x = longitude, y = latitude, color = label_beach), size = 3) +
scale_color_manual(values = pt_color) +
geom_text_repel(data = Sampled_beaches,
aes(x = longitude, y = latitude, label = code,
hjust = ifelse(label_position == "right", 1.3, 0.5),
vjust = ifelse(label_position == "below", 0.5, 0.5)),
size = 5,
color = "black",
fontface = "bold",
box.padding = 0.2,
point.padding = 0.1,
segment.color = "transparent") +
coord_sf(xlim = c(-5.0, -0.2), ylim = c(42.8, 48.0)) +
theme_minimal() +
labs(#title = "Studied area of the Plasfito research project",
color = "Sampled beaches",
fill = "") +
theme(
axis.title.x = element_text(size = 20, face = "bold", vjust = 0.5, margin = margin(t = 10, r = 20, b = 0, l = 0)),
axis.title.y = element_text(size = 20, face = "bold", vjust = 3, margin = margin(t = 0, r = 5, b = 0, l = 0)),
axis.text.x = element_text(size = 12, face = 'bold'),
axis.text.y = element_text(size = 12, face = 'bold'),
title = element_text(size = 22, face = "bold", margin = margin(t = 10, r = 0, b = 20, l = 0)),
strip.text = element_text(face = "bold", size = rel(2)),
strip.background = element_rect(fill = "grey", color = "grey", linewidth = 0.1),
legend.position = "right",
legend.spacing.y = unit(0.1, "cm"),
legend.title = element_text(size = 18, face = 'bold'),
legend.text = element_text(size = 14, face = 'bold')) +
theme(panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5)) + # Add black contour
guides(fill = guide_legend(title = "", order = 1),
color = guide_legend(order = 2))
Plasfito
# Chunk 6: length coastline
# Obtenir les données du trait de côte à haute résolution
coastline <- ne_coastline(scale = 10, returnclass = "sf")
# Définir les points de début et de fin
start_point <- c(-1.260000, 46.320000)
end_point <- c(-4.03000, 43.44000)
# Créer une ligne entre les points de début et de fin
line <- st_sfc(st_linestring(rbind(start_point, end_point)), crs = st_crs(coastline))
# Créer un buffer autour de cette ligne pour capturer le trait de côte
buffer <- st_buffer(line, dist = 0.1)  # Réduire le buffer à 0.1 degré pour plus de précision
# Découper le trait de côte avec ce buffer
coastline_subset <- st_intersection(coastline, buffer)
# Convertir le trait de côte en points avec une résolution plus élevée
coastline_points <- st_cast(coastline_subset, "POINT")
coords <- st_coordinates(coastline_points)
# Calculer la distance le long du trait de côte
total_length <- 0
for (i in 1:(nrow(coords) - 1)) {
total_length <- total_length + distGeo(coords[i, ], coords[i+1, ])
}
# Convertir en kilomètres et arrondir
length_km <- round(total_length / 1000, 2)
print(paste("Longueur estimée du trait de côte :", length_km, "km"))
# Chunk 1: package upload
library(ggplot2)
library(tidyr)
library(forcats)
library(dplyr)
library(readxl)
library(readr)
library(RColorBrewer)
library(tidyverse)
library(binom)
library(lubridate)
library(ade4)
library(ggrepel)
library(broom)
library(ggpubr)
library(rstatix)
library(wesanderson)
library(car)
library(multcompView)
library(rcompanion)
library(writexl)
library(gmodels)
library(openxlsx)
library(fmsb)
#OFW
library(maps)
library(sf)
library(furrr)
library(raster)
library(ggthemes)
library(terra)
library(ncdf4)
library(marmap)
library(rnaturalearth)
library(rnaturalearthdata)
library(rnaturalearthhires)
library(ggspatial)
library(osmdata)
library(grid)
library(devtools)
# Chunk 2: data import
FE_2023 <- read_csv("Datasheets/GFW/public-gfw-v3.0-100924.csv")
FE_2023_2 <- FE_2023 %>%
rename(Time_range = `Time Range`,
Vessel_ID = `Vessel IDs`,
Fishing_h = `Apparent Fishing Hours`,
FG = Geartype) %>%
mutate(Month = month(Time_range, "month", label = F),
Week = week(Time_range),
Week_Year = as.Date(cut(Time_range, "week")),
Year = year(Time_range),
Month_Year = as.Date(format(Time_range, "%Y-%m-01"))) %>%
#Spanish Pole and lines vessels are badly identified and should be "Purse seines"
mutate(FG = if_else(Flag == "ESP" & FG == "pole_and_line", "purse_seines", FG)) %>%
mutate(FG = if_else(Flag == "ESP" & FG == "trollers", "purse_seines", FG)) %>%
mutate(FG = if_else(Flag == "ESP" & FG == "dredge_fishing", "set_gillnets", FG)) %>%
mutate(FG = if_else(FG == "inconclusive" | FG == "fishing" | FG == "fixed_gear", "No specific", FG),
FG = if_else(FG == "tuna_purse_seines" | FG == "other_purse_seines" | FG == "purse_seines", "Purse seines", FG),
FG = if_else(FG == "set_longlines" | FG == "drifting_longlines", "Longlines", FG),
FG = if_else(FG == "trollers" | FG == "pole_and_line", "Pole & lines", FG),
FG = if_else(FG == "seiners" | FG == "other_seines", "Danish seines", FG),
FG = if_else(FG == "pots_and_traps", "Pots & traps", FG),
FG = if_else(FG == "trawlers", "Trawls", FG),
FG = if_else(FG == "set_gillnets", "Gillnets", FG),
FG = if_else(FG == "dredge_fishing", "Dredge fishing", FG))
FE_2023_2
# World polygons from the maps package
world_shp <- sf::st_as_sf(maps::map("world", plot = FALSE, fill = TRUE))
# Get high-resolution data for Europe
europe_high_res <- ne_countries(scale = "large", returnclass = "sf", continent = "Europe")
# Get high-resolution coastline data
coastline_high_res <- ne_coastline(scale = "large", returnclass = "sf")
# Chunk 3: Aggregate data across all fleets and geartypes
effort_all <- FE_2023_2 %>%
group_by(Lon,Lat, FG, Flag) %>%
summarize(fishing_hours = sum(Fishing_h, na.rm = T),
log_fishing_hours = log10(sum(Fishing_h, na.rm = T)+1)) %>%
ungroup()
effort_all
effort_BC <- FE_2023_2 %>%
filter(Lat >= 43.28 & Lat <= 43.75 & Lon >= -4.00 & Lon <= -0.90) %>%
group_by(Lon,Lat, FG) %>%
summarize(fishing_hours = sum(Fishing_h, na.rm = T),
log_fishing_hours = log10(sum(Fishing_h, na.rm = T)+1)) %>%
ungroup()
effort_BC
# Chunk 4: interesting values
effort_avg <- effort_all %>%
group_by(FG) %>%
summarize(sum_fishing_hours = sum(fishing_hours, na.rm = T),
sum_log_fishing_hours = sum(log_fishing_hours, na.rm = T)+1) %>%
ungroup() %>%
arrange(desc(sum_fishing_hours)) %>%
mutate(FE_day = sum_fishing_hours/24)
effort_avg
df_publi <- effort_all %>%
group_by(FG) %>%
summarize(sum_hours = sum(fishing_hours, na.rm = TRUE)) %>%
mutate(percent_hours = round(sum_hours/sum(sum_hours)*100, digits = 2))
df_publi
# Chunk 5: map studied area
#Bathymetry
xlim <- c(-4.00, -0.90)
ylim <- c(43.28, 46.30)
bathy_data <- getNOAA.bathy(lon1 = xlim[1], lon2 = xlim[2],
lat1 = ylim[1], lat2 = ylim[2],
resolution = 1)
bathy_df <- fortify(bathy_data)
# Linear green color palette function
effort_pal <- colorRampPalette(c('#074959', "aquamarine", '#EEFF00'),
interpolate = 'linear')
effort_all$FG = factor(effort_all$FG, levels=c('Pole & lines', 'Dredge fishing',
'Danish seines', 'No specific',
'Purse seines', 'Longlines',
'Gillnets', 'Trawls'))
# Map fishing effort
p1 <- effort_all %>%
ggplot() +
geom_contour(data = bathy_df,
aes(x = x, y = y, z = z, color = after_stat(level)),
breaks = c(-200, -1000, -3000)) +
geom_sf(data = europe_high_res,
fill = '#374a6d',
color = '#0A1738',
size = 0.1) +
geom_tile(aes(x = Lon, y = Lat, fill = log_fishing_hours)) +  # Changé de geom_raster à geom_tile
scale_fill_gradientn(
"Fishing hours\n(log10 scale)",
na.value = NA,
limits = c(0, 3),
colours = effort_pal(5),
labels = c("0", "1", "2", "3"),
values = scales::rescale(c(0, 1))) +
scale_color_gradientn(name = "Depth (m)",
colors = c("#256CB4", "#0096FC", "#A6CEE3"),
breaks = c(-200, -1000, -3000),
labels = c("200", "1000","3000")) +
labs(fill  = 'Fishing hours\n(log scale)',
#title = 'Fishing effort by fleet between November 2022 and November 2023',
x = "Longitudes",
y = "Latitudes") +
guides(fill = guide_colourbar(barwidth = 2, order = 1, title.vjust = -3, barheight = 7.5),
color = guide_legend(order = 2,
override.aes = list(linewidth = 1),
title.vjust = -3)) +
coord_sf(xlim = c(-3.9, -1), ylim = c(46.2, 43.28)) +
#facet_wrap(~FG, nrow = 2) +
theme_classic() +
theme(panel.background = element_rect(fill = "#081028", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 20, face = "bold", vjust = 0.5, margin = margin(t = 10, r = 20, b = 0, l = 0)),
axis.title.y = element_text(size = 20, face = "bold", vjust = 3, margin = margin(t = 0, r = 5, b = 0, l = 0)),
axis.text.x = element_text(size = 12, face = 'bold'),
axis.text.y = element_text(size = 12, face = 'bold'),
title = element_text(size = 22, face = "bold", margin = margin(t = 10, r = 0, b = 20, l = 0)),
strip.text = element_text(face = "bold", size = rel(2)),
strip.background = element_rect(fill = "grey", color = "grey", linewidth = 0.1),
legend.position = "right",
legend.title = element_text(size = 18, face = 'bold'),
legend.text = element_text(size = 14, face = 'bold')
) +
rotate_x_text(angle = 90)
p1
# Chunk 6: map studied area + FE + fishing area FAO
#Bathymetry
xlim <- c(-4.00, -0.90)
ylim <- c(43.28, 46.30)
bathy_data <- getNOAA.bathy(lon1 = xlim[1], lon2 = xlim[2],
lat1 = ylim[1], lat2 = ylim[2],
resolution = 1)
bathy_df <- fortify(bathy_data)
# Linear green color palette function
effort_pal <- colorRampPalette(c('#074959', "aquamarine", '#EEFF00'),
interpolate = 'linear')
effort_all$FG = factor(effort_all$FG, levels=c('Pole & lines', 'Dredge fishing',
'Danish seines', 'No specific',
'Purse seines', 'Longlines',
'Gillnets', 'Trawls'))
# Map fishing effort
p1 <- effort_all %>%
ggplot() +
geom_contour(data = bathy_df,
aes(x = x, y = y, z = z, color = after_stat(level)),
breaks = c(-200, -1000, -3000)) +
geom_sf(data = europe_high_res,
fill = '#374a6d',
color = '#0A1738',
size = 0.1) +
geom_tile(aes(x = Lon, y = Lat, fill = log_fishing_hours)) +  # Changé de geom_raster à geom_tile
scale_fill_gradientn(
"Fishing hours\n(log10 scale)",
na.value = NA,
limits = c(0, 3),
colours = effort_pal(5),
labels = c("0", "1", "2", "3"),
values = scales::rescale(c(0, 1))) +
scale_color_gradientn(name = "Depth (m)",
colors = c("#256CB4", "#0096FC", "#A6CEE3"),
breaks = c(-200, -1000, -3000),
labels = c("200", "1000","3000")) +
labs(fill  = 'Fishing hours\n(log scale)',
#title = 'Fishing effort by fleet between November 2022 and November 2023',
x = "Longitudes",
y = "Latitudes") +
guides(fill = guide_colourbar(barwidth = 2, order = 1, title.vjust = -3, barheight = 7.5),
color = guide_legend(order = 2,
override.aes = list(linewidth = 1),
title.vjust = -3)) +
coord_sf(xlim = c(-3.9, -1), ylim = c(46.2, 43.28)) +
theme_classic() +
theme(panel.background = element_rect(fill = "#081028", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 20, face = "bold", vjust = 0.5, margin = margin(t = 10, r = 20, b = 0, l = 0)),
axis.title.y = element_text(size = 20, face = "bold", vjust = 3, margin = margin(t = 0, r = 5, b = 0, l = 0)),
axis.text.x = element_text(size = 12, face = 'bold'),
axis.text.y = element_text(size = 12, face = 'bold'),
title = element_text(size = 22, face = "bold", margin = margin(t = 10, r = 0, b = 20, l = 0)),
strip.text = element_text(face = "bold", size = rel(2)),
strip.background = element_rect(fill = "grey", color = "grey", linewidth = 0.1),
legend.position = "right",
legend.title = element_text(size = 18, face = 'bold'),
legend.text = element_text(size = 14, face = 'bold')
) +
rotate_x_text(angle = 90)
p1
# Définir les coordonnées corrigées pour la zone de pêche 27.8.b
coords_27_8_b <- data.frame(
lon = c(-4.00, -4.00, -3.00, -3.00, -3.00, -2.50, -2.00, -2.00, -1.00, -1.00, -4.00),
lat = c(46.00, 45.50, 45.50, 45.00, 44.50, 44.50, 44.50, 43.28, 43.28, 46.00, 46.00)
)
coords_27_8_c <- data.frame(
lon = c(-2.00, -2.00, -11.00, -11.00, -2.00),
lat = c(43.28, 44.50, 44.50, 43.00, 43.00)
)
# Ajouter les deux zones à votre carte ggplot existante
p1_fao <- p1 +
geom_path(data = coords_27_8_b, aes(x = lon, y = lat), color = "red", linewidth = 1) +
geom_path(data = coords_27_8_c, aes(x = lon, y = lat), color = "red", linewidth = 1) +
labs(title = "Fishing Areas 27.8.b and 27.8.c")
# Afficher la carte
p1_fao
# Chunk 7: calculate surface area 28.8.c all and plasfito
# Définir les coordonnées pour la zone 27.8.c complète avec une frontière plus précise
coords_27_8_c_complete <- data.frame(
lon = c(-2.00, -2.00, -11.00, -11.00, -9.20, -8.30, -7.80, -7.40, -4.00, -2.00),
lat = c(43.28, 44.50, 44.50, 43.00, 43.00, 43.40, 43.80, 43.60, 43.35, 43.28)
)
# Définir les coordonnées pour la zone 27.8.c coupée
coords_27_8_c_cut <- data.frame(
lon = c(-2.00, -2.00, -4.00, -4.00, -2.00),
lat = c(43.28, 44.50, 44.50, 43.35, 43.28)
)
# Convertir en polygones sf
polygon_complete <- st_polygon(list(as.matrix(coords_27_8_c_complete)))
polygon_cut <- st_polygon(list(as.matrix(coords_27_8_c_cut)))
# Créer des objets sf avec le système de coordonnées approprié
sf_complete <- st_sfc(polygon_complete, crs = 4326)
sf_cut <- st_sfc(polygon_cut, crs = 4326)
# Calculer les surfaces en km²
area_complete <- st_area(sf_complete)/1000000
area_cut <- st_area(sf_cut)/1000000
# Calculer le pourcentage
percentage <- (as.numeric(area_cut) / as.numeric(area_complete)) * 100
percentage
##PLOT
# Définir les limites de la carte
xlim <- c(-11.00, -2.00)
ylim <- c(43.00, 44.50)
# Créer une nouvelle carte avec les mêmes paramètres que p1 mais des limites différentes
bathy_data_large <- getNOAA.bathy(lon1 = xlim[1], lon2 = xlim[2],
lat1 = ylim[1], lat2 = ylim[2],
resolution = 1)
bathy_df_large <- fortify(bathy_data_large)
# Créer la carte
p_278c <- ggplot() +
geom_contour(data = bathy_df_large,
aes(x = x, y = y, z = z, color = after_stat(level)),
breaks = c(-200, -1000, -3000)) +
geom_sf(data = europe_high_res,
fill = '#374a6d',
color = '#0A1738',
size = 0.1) +
scale_color_gradientn(name = "Depth (m)",
colors = c("#256CB4", "#0096FC", "#A6CEE3"),
breaks = c(-200, -1000, -3000),
labels = c("200", "1000","3000")) +
geom_path(data = coords_27_8_c_complete, aes(x = lon, y = lat),
color = "blue", linewidth = 1, linetype = "dashed") +
geom_path(data = coords_27_8_c_cut, aes(x = lon, y = lat),
color = "red", linewidth = 1) +
coord_sf(xlim = c(-11.00, -2.00), ylim = c(43.00, 44.50)) +
labs(x = "Longitudes",
y = "Latitudes",
title = "Fishing Area 27.8.c (complete and cut)") +
theme_classic() +
theme(panel.background = element_rect(fill = "#081028", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size = 12, face = 'bold'),
axis.title = element_text(size = 20, face = "bold"))
p_278c
# Chunk 8: surface lost btw 46.3°N and 46.0°N
# Définir les coordonnées pour la grande zone
coords_grande <- data.frame(
lon = c(-1.00, -4.00, -4.00, -1.00, -1.00),
lat = c(46.30, 46.30, 43.20, 43.20, 46.30)
)
coords_petite<- data.frame(
lon = c(-1.00, -4.00, -4.00, -3.00, -3.00, -4.00, -4.00, -1.00, -1.00),
lat = c(46.00, 46.00, 45.50, 45.50, 44.50, 44.50, 43.20, 43.20, 46.00)
)
# Convertir en polygones sf
polygon_grande <- st_polygon(list(as.matrix(coords_grande)))
polygon_petite <- st_polygon(list(as.matrix(coords_petite)))
# Créer des objets sf avec le système de coordonnées approprié
sf_grande <- st_sfc(polygon_grande, crs = 4326)
sf_petite <- st_sfc(polygon_petite, crs = 4326)
# Calculer les surfaces en km²
area_grande <- st_area(sf_grande)/1000000
area_petite <- st_area(sf_petite)/1000000
# Calculer le pourcentage
percentage <- 100-(as.numeric(area_petite) / as.numeric(area_grande)) * 100
percentage #smaller
#too know by how much I should multiple the small area.
m_factor <- area_grande/area_petite
m_factor
# Chunk 1
library(ggplot2)
library(tidyr)
library(forcats)
library(dplyr)
library(readxl)
library(readr)
library(RColorBrewer)
library(tidyverse)
library(binom)
library(lubridate)
library(ade4)
library(ggrepel)
library(broom)
library(ggpubr)
library(rstatix)
library(wesanderson)
library(car)
library(multcompView)
library(rcompanion)
library(writexl)
library(gmodels)
library(tools)
library(fmsb)
# Chunk 2: import data
surval_modif <- read_excel("Datasheets/surval_modif.xlsx") %>%
separate(coeff, into = c("coeff1", "coeff2"), sep = "/") %>%
mutate(across(c(coeff1, coeff2), as.numeric)) %>%
rowwise() %>%
mutate(coeff_mean = mean(c(coeff1, coeff2), na.rm = TRUE),
surface_m2 = width_high_tide_mark*100) %>%
ungroup() %>%
rename(width_beach = width_high_tide_mark)
surval_modif
# Chunk 3: regression width vs. coeff
surval_low <- surval_modif %>%
filter(tide == "low"| tide == "middle")
surval_low
surval_high <- surval_modif %>%
filter(tide == "high")
surval_high
CrossTable(surval_modif$site)
G_reg <- surval_low%>%
ggplot(aes(x = coeff_mean, y = width_beach, color = tide)) +
geom_point() +
geom_smooth(method = "lm", se = T, color = "black") +
facet_wrap(~site, scales = "free")
G_reg
# Chunk 4
avg_width_low <- surval_low %>%
group_by(Country, North_South, site) %>%
summarise(n_L = n(),
avg_width_L = mean(width_beach, na.rm = TRUE),
sd_width_L = sd(width_beach, na.rm = TRUE),
avg_surface_L = mean(surface_m2, na.rm = TRUE),
sd_surface_L = sd(surface_m2, na.rm = TRUE))
avg_width_low
avg_width_high <- surval_high %>%
group_by(Country, North_South, site) %>%
summarise(n_H = n(),
avg_width_H = mean(width_beach, na.rm = TRUE),
sd_width_H = sd(width_beach, na.rm = TRUE),
avg_surface_H = mean(surface_m2, na.rm = TRUE),
sd_surface_H = sd(surface_m2, na.rm = TRUE))
avg_width_high
avg_joined <- left_join(avg_width_low, avg_width_high, by = c("site", "Country", "North_South")) %>%
filter(site != "Le Teich") %>% mutate(cov_rate_S = 100-(avg_surface_H*100/avg_surface_L)) %>%
rename(Site_long = site,
Site = North_South)
avg_joined
avg_for_join <- avg_joined %>%
ungroup() %>%
dplyr::select(Site, avg_surface_L)
#write_xlsx(avg_for_join, "Datasheets/avg_for_join.xlsx")
#Mean beach coverage at high tide
avg_cv_HT <- avg_joined %>%
group_by(Country) %>%
summarise(avg_cov_rate_S = mean(cov_rate_S, na.rm = TRUE),
sd_cov_rate_S = sd(cov_rate_S, na.rm = TRUE))
avg_cv_HT
# Chunk 5: stat coverage
df_stat <- avg_joined %>%
dplyr::select(Country, cov_rate_S)
df_stat
france_data <- df_stat$cov_rate_S[df_stat$Country == "France"]
shapiro.test(france_data)
spain_data <- df_stat$cov_rate_S[df_stat$Country == "Spain"]
shapiro.test(spain_data)
par(mfrow=c(1,2))
qqnorm(france_data, main="Q-Q Plot France")
qqline(france_data)
qqnorm(spain_data, main="Q-Q Plot Espagne")
qqline(spain_data)
#Statistical test for the coverage rate
##t-test
t_test <- t.test(france_data, spain_data)
t_test
##MWU
wilcox.test(cov_rate_S ~ Country, data = df_stat)
